{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Discombibleator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "measures = pd.read_csv(\"data/measures.csv\", header = 0, index_col = 0, squeeze=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_roots = pd.read_csv('data/measurement_roots.csv', header=0, index_col=1, squeeze=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biblical_Measurement:\n",
    "    \n",
    "    def __init__(self, string, units = \"imperial\"):\n",
    "        self.string = string\n",
    "        self.tokenized_string = word_tokenize(self.string)\n",
    "        self.units = units\n",
    "        self.measurement_found = False\n",
    "        self.lemmatized = False\n",
    "        self.nums_converted = False\n",
    "        self.multiword_signifiers = [\"hour\", \"watch\", \"journey\",\n",
    "                                    \"walk\", \"cubit\", \"cubits\"]\n",
    "        self.ordinal_times = [\"second\", \"third\", \"fourth\", \"sixth\",\n",
    "                            \"seventh\", \"ninth\", \"tenth\", \"eleventh\"]\n",
    "        self.punctuation = [\".\", \";\", \",\", \"!\", \"?\", \"(\", \")\", \":\"]\n",
    "    \n",
    "    def Concat_Multiword(self):\n",
    "        if any(np.intersect1d(self.tokenized_string, self.multiword_signifiers)):\n",
    "            for i, j in enumerate(self.tokenized_string):\n",
    "                if j in self.multiword_signifiers:\n",
    "                    if self.tokenized_string[i-1] in self.ordinal_times:\n",
    "                        self.tokenized_string[i-2:i+1] = [\" \".join(self.tokenized_string[i-2:i+1])]\n",
    "                    elif j in (\"journey\", \"walk\"):\n",
    "                        if self.tokenized_string[i-2] in (\"Sabbath\", \"sabbath\"):\n",
    "                            self.tokenized_string[i-2:i+1] = [\"sabbath day's journey\"]\n",
    "                        else:\n",
    "                            self.tokenized_string[i-1:i+1] = [\"day's journey\"]\n",
    "                    elif j in (\"cubit\", \"cubits\"):\n",
    "                        if self.tokenized_string[i-1] == 'long':\n",
    "                            self.tokenized_string[i-1:i+1] = [\" \".join(self.text_list[i-1:i+1])]\n",
    "        self.tokenized_string = self.tokenized_string                  \n",
    "        \n",
    "    def Has_Measure_Words(self):\n",
    "        if any(s in self.tokenized_string for s in measurement_roots.keys()): # change to assertion\n",
    "            self.measurement_found = True \n",
    "        elif any(s in self.tokenized_string for s in measurement_roots.values()): # change to assertion\n",
    "            self.measurement_found = True \n",
    "        else:\n",
    "            print(\"Measurement to be converted not found in input text:\\n{}\".format(self.string))\n",
    "            \n",
    "    def Lemmatize_Measure_Words(self):\n",
    "        if self.measurement_found: #change to assertion\n",
    "            for word in set(self.tokenized_string).intersection(measurement_roots.keys()):\n",
    "                self.tokenized_string[:] = [measurement_roots[word] if x == word else x for x in self.tokenized_string]\n",
    "            self.lemmatized = True\n",
    "    \n",
    "    def Represents_Int(self, s):\n",
    "        try: \n",
    "            int(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "        \n",
    "    def Number_Converter(self, num, measure_word):\n",
    "        if self.units == \"metric\":\n",
    "            num = float(num) * float(measures['metric_multiplier'][measure_word])\n",
    "        else:\n",
    "            num = float(num) * float(measures['imperial_multiplier'][measure_word])\n",
    "        return str(num)\n",
    "    \n",
    "    def Measure_Word_Converter(self, word):\n",
    "        return (measures[self.units][word])\n",
    "    \n",
    "    def Find_Convert_Numbers(self):\n",
    "        if self.lemmatized: # turn into assertion\n",
    "            for i, j in enumerate(self.tokenized_string):\n",
    "                if j in measurement_roots.values():\n",
    "                    for unit in self.tokenized_string[:i]: # I don't like that this might look so extensively back.\n",
    "                        if (i - self.tokenized_string.index(unit)) <= 4:\n",
    "                            unit_locator = self.tokenized_string.index(unit)\n",
    "                            if self.Represents_Int(unit):\n",
    "                                self.tokenized_string[unit_locator] = self.Number_Converter(unit, j)\n",
    "                            elif unit in (\"a\", \"an\", \"the\", \"A\", \"An\", \"The\"):\n",
    "                                if(self.tokenized_string.index(j) - unit_locator) in range(2):\n",
    "                                    self.tokenized_string[unit_locator] = self.Number_Converter(1, j)\n",
    "            self.nums_converted = True\n",
    "            \n",
    "    def Convert_Measure_Words(self):\n",
    "        if self.nums_converted: # turn into assertion\n",
    "            for i, j in enumerate(self.tokenized_string):\n",
    "                if j in measurement_roots.values():\n",
    "                    self.tokenized_string[i] = self.Measure_Word_Converter(j)\n",
    "                    \n",
    "    def Join_Elements(self):\n",
    "        for element in self.tokenized_string:\n",
    "            output = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in self.punctuation else i for i in self.tokenized_string]).strip()\n",
    "        return output\n",
    "            \n",
    "class Verse:\n",
    "    \n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "        \n",
    "    def Return_String(self):\n",
    "        return self.string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was 135.0 inches and we saw it during between 9 PM and midnight.'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Verse(\"It was 15 spans and we saw it during the second watch.\")\n",
    "y.Return_String()\n",
    "\n",
    "x = Biblical_Measurement(y.Return_String())\n",
    "x.Concat_Multiword()\n",
    "x.Has_Measure_Words()\n",
    "x.Lemmatize_Measure_Words()\n",
    "x.Find_Convert_Numbers()\n",
    "x.Convert_Measure_Words()\n",
    "x.Join_Elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was 18.0 feet tall and we saw it during 3:00 PM.'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Biblical_Measurement(\"It was 12 cubits tall and we saw it during the ninth hour.\")\n",
    "x.concat_multiword()\n",
    "x.has_measure_words()\n",
    "x.lemmatize_measure_words()\n",
    "x.find_convert_numbers()\n",
    "x.convert_measure_words()\n",
    "x.join_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was 18.0 or 19.5 feet tall and we saw it during 3:00 PM'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Biblical_Measurement(\"It was 12 or 13 cubits tall and we saw it during the ninth hour\")\n",
    "x.concat_multiword()\n",
    "x.has_measure_words()\n",
    "x.lemmatize_measure_words()\n",
    "x.find_convert_numbers()\n",
    "x.convert_measure_words()\n",
    "x.join_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.9 gallons of wine cost 900.0 or 975.0 pounds of gold and 3.62 USD; and we saw it during 3:00 PM.'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Biblical_Measurement(\"The bath of wine cost 12 or 13 talents of gold and a denarius; and we saw it during the ninth hour.\")\n",
    "x.concat_multiword()\n",
    "x.has_measure_words()\n",
    "x.lemmatize_measure_words()\n",
    "x.find_convert_numbers()\n",
    "x.convert_measure_words()\n",
    "x.join_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
